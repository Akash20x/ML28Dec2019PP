{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Your Own Word2Vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec model can learn embeddings from any text corpus!\n",
    "- Continuous Bag of Words Model\n",
    "- Skip Gram Model\n",
    "\n",
    "`Algorithm looks at window of target word(Y) to provide context word(X), the model is trained on (X,Y) pairs in a superwised manner.` The algorithm was developed by Tomas Mikolov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Each sentence must be tokenized, into a list of words.\n",
    "\n",
    "- The sentences can be text loaded into memory once,\n",
    "or we can build a data pipeline which iteratively feeds data to the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "with open('bollywood.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    data = []\n",
    "    for sent in sentences:\n",
    "        words = word_tokenize(sent)\n",
    "        words = [w.lower() for w in words if w not in sw and len(w)>2]\n",
    "        data.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['deepika', 'padukone', 'ranveer', 'singh', 'wedding', 'one', 'biggest', 'bollywood', 'events', 'happened', '2018'], ['the', 'deepika', 'ranveer', 'celebrations', 'hooked', 'phones', 'waiting', 'come', 'also', 'gave', 'enough', 'reason', 'believe', 'stylish', 'two', 'couple'], ['from', 'airport', 'looks', 'reception', 'parties', 'everything', 'entire', 'timeline', 'deepika', 'ranveer', 'wedding', 'style', 'file'], ['not', 'ambanis', 'deepika', 'ranveer', 'priyanka', 'nick'], ['man', 'proves', 'wedding', 'the', 'year', 'this', 'year', 'year', 'big', 'fat', 'lavish', 'extravagant', 'weddings'], ['from', 'isha', 'ambani', 'anand', 'piramal', 'deepika', 'padukone', 'ranveer', 'singh', 'priyanka', 'chopra', 'nick', 'jonas', 'kapil', 'sharma', 'ginni', 'chatrath', '2018', 'saw', 'many', 'grand', 'weddings'], ['but', 'nothing', 'beats', 'man', 'wedding', 'the', 'year', 'award', 'social', 'media'], ['priyanka', 'also', 'shared', 'video', 'featuring', 'nick', 'jonaswas', 'also', 'celebrating', 'the', 'family', 'first', 'celebrated', 'christmas', 'london', 'pictures', 'priyanka', 'chopra', 'nick', 'jonas', 'new', 'year', 'celebrations', 'outstanding'], ['priyanka', 'chopra', 'nick', 'shared', 'glimpses', 'celebration', 'verbier', 'switzerland'], ['priyanka', 'chopra', 'married', 'nick', 'jonas', 'december', 'three', 'wedding', 'receptions', 'one', 'new', 'delhi', 'two', 'mumbai'], ['this', 'year', 'year', 'big', 'fat', 'lavish', 'extravagant', 'weddings'], ['from', 'isha', 'ambani', 'anand', 'piramal', 'deepika', 'padukone', 'ranveer', 'singh', 'priyanka', 'chopra', 'nick', 'jonas', 'kapil', 'sharma', 'ginni', 'chatrath', '2018', 'saw', 'many', 'grand', 'weddings'], ['but', 'nothing', 'beats', 'man', 'wedding', 'the', 'year', 'award', 'social', 'media'], ['kapil', 'sharma', 'ginni', 'chatrath', 'jaggo', 'night', 'december', 'made', 'even', 'special', 'industry', 'friends'], ['kapil', 'sharma', 'ginni', 'chatrath', 'friends', 'long', 'time'], ['there', 'virat', 'side', 'actress', 'wife', 'anushka', 'sharma', 'pleasure', 'audience'], ['while', 'couple', 'rang', 'new', 'year', 'style', 'morning', 'saw', 'virat', 'dress', 'squad', 'attire', 'anushka', 'pink', 'salwar', 'suit'], ['isha', 'ambani', 'married', 'anand', 'piramal', 'year']]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(data, size=300, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=116, size=300, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deepika', 'padukone', 'ranveer', 'singh', 'wedding', 'one', 'biggest', 'bollywood', 'events', 'happened', '2018', 'the', 'celebrations', 'hooked', 'phones', 'waiting', 'come', 'also', 'gave', 'enough', 'reason', 'believe', 'stylish', 'two', 'couple', 'from', 'airport', 'looks', 'reception', 'parties', 'everything', 'entire', 'timeline', 'style', 'file', 'not', 'ambanis', 'priyanka', 'nick', 'man', 'proves', 'year', 'this', 'big', 'fat', 'lavish', 'extravagant', 'weddings', 'isha', 'ambani', 'anand', 'piramal', 'chopra', 'jonas', 'kapil', 'sharma', 'ginni', 'chatrath', 'saw', 'many', 'grand', 'but', 'nothing', 'beats', 'award', 'social', 'media', 'shared', 'video', 'featuring', 'jonaswas', 'celebrating', 'family', 'first', 'celebrated', 'christmas', 'london', 'pictures', 'new', 'outstanding', 'glimpses', 'celebration', 'verbier', 'switzerland', 'married', 'december', 'three', 'receptions', 'delhi', 'mumbai', 'jaggo', 'night', 'made', 'even', 'special', 'industry', 'friends', 'long', 'time', 'there', 'virat', 'side', 'actress', 'wife', 'anushka', 'pleasure', 'audience', 'while', 'rang', 'morning', 'dress', 'squad', 'attire', 'pink', 'salwar', 'suit']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['deepika'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.44092215e-03,  2.69657292e-04,  1.50082808e-03, -8.05233431e-04,\n",
       "        1.90877297e-04, -9.89122665e-04,  1.18747761e-03, -1.52962306e-03,\n",
       "       -6.61236933e-04,  8.82194785e-04, -1.04016124e-03,  1.93682339e-04,\n",
       "        1.32358156e-03, -1.44713395e-03,  1.33452460e-03,  1.13327603e-03,\n",
       "        1.26779743e-03,  1.38444698e-03, -1.55230775e-03,  1.21903303e-03,\n",
       "        1.75473644e-04,  2.65393581e-04,  1.72259170e-04,  8.50962606e-05,\n",
       "       -1.61960907e-03, -5.88213734e-04,  1.60836359e-03,  9.91995985e-05,\n",
       "       -1.60788535e-03,  6.71664195e-04, -5.78499225e-04,  7.95483880e-04,\n",
       "        1.03943734e-04,  1.02804624e-03, -3.84471554e-04,  4.30128421e-05,\n",
       "        9.53660565e-05,  1.43488683e-03,  1.15316932e-03,  9.92862042e-04,\n",
       "       -1.22958489e-04,  1.33881904e-03, -2.48046970e-04, -5.52785757e-04,\n",
       "        1.12698786e-03, -1.46097655e-03,  1.61723612e-04, -1.18425081e-03,\n",
       "       -8.16246495e-04, -1.26065256e-03, -7.76827394e-04,  1.02788070e-03,\n",
       "        1.37063267e-03, -2.59705630e-05,  1.30189885e-03, -1.04986539e-03,\n",
       "        8.06097116e-04,  1.40362745e-03, -9.33790754e-04, -1.52822421e-03,\n",
       "        7.42290518e-04, -1.18735933e-03,  1.62878621e-03, -1.42725461e-04,\n",
       "       -1.22966222e-03,  2.84425303e-04,  1.01979160e-04,  2.49890923e-06,\n",
       "       -4.89035272e-04,  1.12054893e-03,  5.52797224e-04,  3.77390505e-04,\n",
       "        6.96172705e-04, -1.36550132e-03, -1.38273335e-03,  4.81576484e-04,\n",
       "       -1.06910255e-03,  8.86412687e-04,  9.62393533e-04, -1.66368077e-03,\n",
       "       -5.36377192e-05,  2.32861257e-05,  6.68573310e-04,  1.48418441e-03,\n",
       "       -1.53344963e-03, -8.53074773e-04,  1.97125948e-04, -1.23874680e-03,\n",
       "       -8.16116517e-04,  7.09070475e-04, -1.02951564e-03, -1.55602500e-03,\n",
       "       -1.58740592e-03,  8.30983990e-05,  1.56651414e-03, -1.27238221e-03,\n",
       "       -1.27531670e-03, -5.39933739e-04,  9.16612975e-04, -1.69579318e-04,\n",
       "       -7.58990995e-04, -2.71169731e-04, -7.19219155e-04, -1.07577315e-03,\n",
       "        1.11870468e-03, -7.57073110e-04, -1.04857422e-03, -2.70022254e-04,\n",
       "       -1.05052162e-03, -5.65358241e-05, -1.30879856e-03,  6.76737109e-04,\n",
       "        9.61999060e-04,  2.45598494e-04,  1.11287845e-04, -1.10924608e-04,\n",
       "       -1.08974054e-03,  1.26724888e-03, -3.28957714e-04,  1.15448202e-03,\n",
       "       -1.18739856e-03,  1.32508576e-03, -1.52309414e-03, -6.85847132e-04,\n",
       "       -1.53024588e-03, -1.53984036e-03, -1.06150785e-03, -3.15719051e-04,\n",
       "       -4.47833678e-04,  4.14974173e-04, -2.95056871e-05,  1.37783389e-03,\n",
       "       -2.87118892e-04,  1.33233925e-03,  8.46329960e-04,  1.67139876e-03,\n",
       "        1.36123411e-03, -6.46998742e-05,  7.64333701e-04,  4.65480814e-04,\n",
       "        6.42360712e-04, -2.23905008e-04,  1.36149942e-03, -2.88254087e-04,\n",
       "        9.15403129e-04, -1.85293429e-05,  1.05521223e-03, -9.06458183e-04,\n",
       "       -1.27412996e-03, -4.08393331e-04,  4.89217753e-04,  1.41985109e-03,\n",
       "        1.66755856e-03, -9.19701299e-04, -1.40588800e-03,  1.71341177e-04,\n",
       "        1.04642613e-03,  1.60003384e-03, -8.07001838e-04, -1.21145463e-03,\n",
       "       -1.04602438e-03,  7.31988635e-04,  1.22651190e-03,  1.55651092e-03,\n",
       "       -1.50035659e-03,  1.09060120e-03,  8.43774702e-04,  1.50123946e-04,\n",
       "        2.41789763e-04,  4.03110113e-04, -1.82563745e-04, -9.53804876e-04,\n",
       "       -7.94579275e-04, -5.46908181e-04,  1.41749298e-03,  4.26097453e-04,\n",
       "        1.59338451e-04,  6.98966251e-05,  1.29544607e-03,  5.82275563e-04,\n",
       "        5.79375483e-04, -9.20399558e-04, -7.66778772e-04, -6.94493589e-04,\n",
       "        9.91358975e-05,  2.13414387e-04, -4.18892771e-04,  9.11390234e-04,\n",
       "       -1.24984945e-03,  8.61602370e-04, -3.57137265e-04,  1.03700440e-03,\n",
       "       -1.66115863e-03, -4.82468284e-04, -5.62402885e-04, -5.34068095e-04,\n",
       "       -8.68172676e-04,  2.89085419e-05,  8.54587823e-04,  1.00067246e-03,\n",
       "       -1.14066841e-03,  5.60831686e-04, -7.89645070e-04,  1.11507438e-03,\n",
       "       -1.02531267e-04,  2.58705433e-04,  8.26045871e-04, -5.63662383e-04,\n",
       "       -7.30201951e-04,  8.17684748e-04, -8.34423467e-04, -1.72208733e-04,\n",
       "       -7.10949302e-04,  1.14978594e-03, -1.21667993e-03, -1.54560292e-03,\n",
       "        8.69893411e-04, -1.38172833e-03, -1.58795074e-03, -1.57182547e-03,\n",
       "        6.18250691e-04,  8.86355876e-04, -6.23070053e-04,  2.71292647e-05,\n",
       "       -4.00127901e-05, -1.03370263e-03,  1.57464834e-04,  3.11109732e-04,\n",
       "        1.01818691e-03,  6.80826488e-04,  3.48000758e-04,  1.29343721e-03,\n",
       "       -9.96952294e-04,  4.33242094e-04,  1.04190595e-03,  8.34856008e-04,\n",
       "       -1.01220445e-04, -1.53539027e-03, -7.44516728e-04, -1.09963550e-03,\n",
       "       -5.66053845e-04, -1.57020043e-03, -5.79266169e-04, -5.08513534e-04,\n",
       "       -2.18807938e-04, -4.21815697e-04, -2.90809228e-04,  3.07864335e-04,\n",
       "       -1.51505170e-03,  3.59283818e-04,  1.42706325e-03,  2.23706549e-04,\n",
       "       -1.26162556e-03, -1.13259640e-03, -1.45369978e-03, -2.83213827e-04,\n",
       "        4.20961151e-04,  8.28240227e-05, -1.53493928e-03,  1.54828781e-03,\n",
       "       -1.08482677e-03, -1.33730704e-03, -1.33378722e-03,  1.20939035e-03,\n",
       "       -8.52019177e-04,  1.38991827e-03,  6.14514574e-04,  1.45762600e-03,\n",
       "       -3.63215513e-04,  6.09135139e-04,  6.41693710e-04,  1.34448626e-03,\n",
       "        9.56960663e-04, -9.28144960e-04, -1.35008362e-03, -1.14409230e-03,\n",
       "        4.86694276e-04,  7.11090281e-04, -7.03683007e-04,  1.05706812e-03,\n",
       "        1.54308265e-03, -1.30257205e-04, -5.10439626e-04, -9.11997864e-04,\n",
       "       -5.33118400e-05,  1.22264633e-03,  1.53431296e-03,  1.43070181e-03,\n",
       "       -8.30578734e-04, -3.11291835e-04,  6.35506469e-04,  1.05317647e-03,\n",
       "       -1.66382606e-03, -9.80852754e-04, -1.32846902e-03, -9.97724361e-04,\n",
       "        3.82739410e-04,  1.50507397e-03, -2.21826500e-04, -8.54697835e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['ranveer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors = [\"ranveer\", \"deepika\", \"padukone\", \"singh\", \"nick\", \"jonas\", \"priyanka\", \"chopra\", \"virat\", \"anushka\"]\n",
    "\n",
    "def predict_word(a,b,c):\n",
    "    a,b,c = a.lower(), b.lower(), c.lower()\n",
    "    \n",
    "    # similarity |b-a| = |d-c|  should be max\n",
    "    max_sim = -100\n",
    "    \n",
    "    d = None\n",
    "    \n",
    "    \n",
    "    wa,wb,wc = model.wv[a], model.wv[b], model.wv[c]\n",
    "    \n",
    "    for w in actors:\n",
    "        if w in [a,b,c]:\n",
    "            continue\n",
    "        \n",
    "        wd = model.wv[w]\n",
    "        sim = cosine_similarity([wb-wa], [wd-wc])\n",
    "        \n",
    "        if sim> max_sim:\n",
    "            max_sim = sim\n",
    "            d = w\n",
    "            \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deepika'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triad = (\"nick\", \"priyanka\", \"virat\")\n",
    "predict_word(*triad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deepika'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triad = (\"virat\", \"anushka\", \"nick\")\n",
    "predict_word(*triad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chopra'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triad = (\"deepika\", \"padukone\", \"priyanka\")\n",
    "predict_word(*triad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
