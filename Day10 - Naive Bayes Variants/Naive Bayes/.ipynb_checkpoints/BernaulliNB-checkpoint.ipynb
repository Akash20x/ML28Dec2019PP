{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "import glob\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(text):\n",
    "    \"\"\"Extracts features from text\n",
    "    \n",
    "    Args:\n",
    "        text (str): Any document containing strings\n",
    "    Returns:\n",
    "        Set of all the unique words in the document.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return set([w.lower() for w in text.split(\" \")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" initialize all probabilities with None\"\"\"\n",
    "log_priors = None\n",
    "cond_probs = None\n",
    "features = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(documents, labels):\n",
    "    \"\"\"Train a Bernoulli naive Bayes classifier\n",
    "\n",
    "    Args:\n",
    "        documents (list): Each element in this list\n",
    "            is a text\n",
    "        labels (list): The ground truth label for\n",
    "            each document\n",
    "    \"\"\"\n",
    "    global log_priors\n",
    "    global cond_probs\n",
    "    global features     \n",
    "    \n",
    "    \n",
    "    \"\"\"Compute log( P(Y) )\"\"\"\n",
    "    label_counts = Counter(labels)\n",
    "    N = float(sum(label_counts.values()))\n",
    "    log_priors = {k: log(v/N) for k, v in label_counts.items()}\n",
    "\n",
    "    \n",
    "    \"\"\"Feature extraction\"\"\"\n",
    "    # Extract features from each document\n",
    "    X = [set(get_features(d)) for d in documents]      # Vectorize X\n",
    "\n",
    "    # Get all features\n",
    "    features = set([f for features in X for f in features])\n",
    "\n",
    "    \n",
    "    \"\"\"Compute log( P(X|Y) )\n",
    "\n",
    "       Use Laplace smoothing v + 1 / N + 2)\"\"\"\n",
    "    \n",
    "    \n",
    "    # Structure for conditional Probabs\n",
    "    cond_probs = {l: {f: 0. for f in features} for l in log_priors}\n",
    "\n",
    "    # Step through each document - fill cond_probabs\n",
    "    for f in features:\n",
    "        for x, l in zip(X, labels):\n",
    "            if f in x:\n",
    "                cond_probs[l][f] += 1.\n",
    "\n",
    "                \n",
    "    # Now, compute log probs\n",
    "    for l in cond_probs:\n",
    "        N = label_counts[l]\n",
    "        cond_probs[l] = {f: (v + 1.) / (N + 2.) for f, v in cond_probs[l].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    \"\"\"Make a prediction from text\"\"\"\n",
    "\n",
    "    global log_priors\n",
    "    global cond_probs\n",
    "    global features     \n",
    "\n",
    "    \n",
    "    \n",
    "    # Extract features\n",
    "    x = get_features(text)\n",
    "\n",
    "    pred_class = None\n",
    "    max_ = float(\"-inf\")\n",
    "\n",
    "    # Compute posterior probability for all classes\n",
    "    for l in log_priors:\n",
    "        log_sum = log_priors[l]\n",
    "        for f in features:\n",
    "            prob = cond_probs[l][f]\n",
    "            log_sum += log(prob if f in x else 1. - prob)\n",
    "        if log_sum > max_:\n",
    "            max_ = log_sum\n",
    "            pred_class = l\n",
    "\n",
    "    return pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labeled_data(type_):\n",
    "\n",
    "    examples = []\n",
    "    labels = []\n",
    "\n",
    "    file_names = glob.glob('./ex6DataEmails/spam-{0}/*.txt'.format(type_))\n",
    "    for n in file_names:\n",
    "        f = open(n)\n",
    "        examples.append(f.read())\n",
    "        labels.append('spam')\n",
    "        f.close()\n",
    "\n",
    "    file_names = glob.glob('./ex6DataEmails/nonspam-{0}/*.txt'.format(type_))\n",
    "    for n in file_names:\n",
    "        f = open(n)\n",
    "        examples.append(f.read())\n",
    "        labels.append('nonspam')\n",
    "        f.close()\n",
    "\n",
    "    return examples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 700\n",
      "Number of test examples: 260\n"
     ]
    }
   ],
   "source": [
    "train_docs, train_labels = get_labeled_data('train')\n",
    "test_docs, test_labels = get_labeled_data('test')\n",
    "\n",
    "# Train model\n",
    "print('Number of training examples: {0}'.format(len(train_labels)))\n",
    "print('Number of test examples: {0}'.format(len(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Training complete!\n",
      "Number of features found: 19100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Training model...')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train(train_docs, train_labels)\n",
    "\n",
    "\n",
    "\n",
    "print('Training complete!')\n",
    "\n",
    "\n",
    "print('Number of features found: {0}'.format(len(features)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n",
      "spam\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0])\n",
    "print(predict(test_docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model...\n",
      "Error rate of 4.231% (11/260)\n"
     ]
    }
   ],
   "source": [
    "# Simple error test metric\n",
    "print('Testing model...')\n",
    "\n",
    "f = lambda doc, l: 1. if predict(doc) != l else 0.\n",
    "num_missed = sum([f(doc, l) for doc, l in zip(test_docs, test_labels)])\n",
    "\n",
    "\n",
    "N = len(test_labels) * 1.\n",
    "error_rate = round(100. * (num_missed / N), 3)\n",
    "\n",
    "print('Error rate of {0}% ({1}/{2})'.format(error_rate, int(num_missed), int(N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"apple\", \"mango\", \"banana\"]\n",
    "b = [40, 50, 90]\n",
    "c = [\"planet\", \"earth\" , \"moon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('apple', 40, 'planet')\n",
      "('mango', 50, 'earth')\n",
      "('banana', 90, 'moon')\n"
     ]
    }
   ],
   "source": [
    "for k in zip(a,b, c):\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
